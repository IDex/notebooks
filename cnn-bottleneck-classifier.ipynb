{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, extra_trees, any_preprocessing, svc, xgboost_classification\n",
    "from hyperopt import tpe, hp\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import linear_model, ensemble, svm, model_selection, dummy, feature_selection, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = MobileNet(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "img_path = 'phos/a00289bff4a2699940f08833e727ea34338997bf.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data bottleneck preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_predictions(cs=None, model=None):\n",
    "    data = []\n",
    "    for i,c in enumerate(cs):\n",
    "        for fd in c:\n",
    "            fs = os.listdir(fd+'/')\n",
    "            n=0\n",
    "            for f in fs:\n",
    "                n+=1\n",
    "                if not n%50:\n",
    "                    print(n,i,f)\n",
    "                img_path = fd+'/'+f\n",
    "                img = image.load_img(img_path, target_size=input_shape[:-1])\n",
    "                x = image.img_to_array(img)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "                features = model.predict(x)\n",
    "                yield dict(features=features, c=i)\n",
    "    raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict((x for x in calc_predictions(cs=[['phosifier/sank/not-phos',],['phosifier/sank/phos',]], model=model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data saving/loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_json('mobilenet-data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_json('mobilenet-sank-avg-data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_json('inresv3-data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_json('mobilenet-data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_json('mobilenet-sank-avg-data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.features.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf=df.features.apply(lambda x: sc.array(x).flatten())[0].shape[0]\n",
    "df.features.apply(lambda x: sc.array(x).flatten())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.features = df.features.apply(lambda x: sc.array(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.features.values\n",
    "# make 1d array of 1d arrays -> 2d array\n",
    "X = sc.array(X.tolist())\n",
    "r = df.c.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtot = X\n",
    "rtot = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Xt,r,rt = model_selection.train_test_split(X,r,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "Various classifiers fitted on data\n",
    "\n",
    "Below a table of performance of logistic regression on various sets and poolings\n",
    "\n",
    "|Net|Pooling|LinCV|LinTest|Best|TestSplit|Train data|\n",
    "|:-|:-|:-|:-|:-|\n",
    "|MobileNet|avg|.79|.81|.83|.2|sank|\n",
    "|MobileNet|max|.79|.83|.|.2|sank|\n",
    "|MobileNet|none|.|.|.|.2|sank|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = linear_model.LogisticRegressionCV(cv=10).fit(X,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.scores_[1].mean(axis=0), m.scores_[1].mean(axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = linear_model.LogisticRegressionCV(cv=10).fit(Xtot,rtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.cross_val_score(m, Xtot, rtot, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idxs=m.coef_[0].argpartition(-5)[-5:]\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idxs:\n",
    "    plt.figure()\n",
    "    sns.distplot([x[idx] for x,r in zip(X,r) if r])\n",
    "    sns.distplot([x[idx] for x,r in zip(X,r) if not r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble.GradientBoostingClassifier(n_estimators=2**6).fit(X,r).score(Xt,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1291.54966501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.C_, m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = linear_model.LogisticRegression(C=1291).fit(X,r)\n",
    "m2.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = linear_model.LogisticRegression()\n",
    "m3.fit(X,r)\n",
    "m3.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = linear_model.LogisticRegression(penalty='l1').fit(X,r)\n",
    "m4.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(m4.coef_[0]!=0), len(m4.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mm = feature_selection.SelectFromModel(linear_model.LogisticRegression(penalty='l1')).fit(X,r)\n",
    "nX = mm.transform(X)\n",
    "nXt = mm.transform(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mmf1 = ensemble.RandomForestClassifier(n_estimators=2**9, n_jobs=-1)\n",
    "mmf1.fit(nX,r)\n",
    "mmf1.score(nXt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1 = svm.LinearSVC().fit(X,r)\n",
    "ms1.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ms2 = svm.SVC(kernel='rbf')\n",
    "ms2 = model_selection.RandomizedSearchCV(ms2, param_distributions=dict(C=sc.stats.expon(0,10)), cv=5, n_iter=10)\n",
    "ms2.fit(X,r)\n",
    "ms2.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2 = svm.SVC(kernel='rbf')\n",
    "ms2.fit(X,r)\n",
    "ms2.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mf1 = ensemble.RandomForestClassifier(n_estimators=2**7, n_jobs=-1)\n",
    "mf1.fit(X,r)\n",
    "mf1.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf2 = ensemble.ExtraTreesClassifier(n_estimators=2**6, n_jobs=-1)\n",
    "mf2.fit(X,r)\n",
    "mf2.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = dummy.DummyClassifier().fit(X,r)\n",
    "md.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General hyperparameter optimizers\n",
    "Using hyperopt for finding a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estim = HyperoptEstimator(classifier=any_classifier('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_prp'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=200,\n",
    "                          verbose=1,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = HyperoptEstimator(classifier=svc('clf'),\n",
    "                          preprocessing=any_preprocessing('my_prp'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=200,\n",
    "                          verbose=1,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estim.fit(Xtot, rtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estim.score( Xt, rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [x for x in estim.trials.losses() if x]\n",
    "sns.distplot(losses)\n",
    "len(losses)/len(estim.trials.losses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "sc.sum(sc.array(losses)[sc.array(losses).argpartition(7)[:7][-1]]>sc.array(losses))\n",
    "#sc.array(losses)[]\n",
    "sc.array(losses).argpartition(5)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durs = [x['duration'] for x in estim.trials.results if x['status']=='ok']\n",
    "sns.distplot(durs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.mean(sc.array(durs)<200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = estim.best_model()['learner']\n",
    "print(estim.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(mh)==svm.classes.SVC:\n",
    "    mh.probability = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.fit(Xtot,rtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh.score(Xt,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.cross_val_score(mh, Xt, rt, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.cross_val_score(mh, X, r, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.cross_val_score(mh, Xtot, rtot, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(fp, c, model, clf, clf2=None, print_wrong=True, print_right=False):\n",
    "    img_path = fp\n",
    "    img = image.load_img(img_path, target_size=input_shape[:-1])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)\n",
    "    features = features.flatten().reshape(1, -1)\n",
    "    probs = []\n",
    "    y_pred = clf.predict(features)\n",
    "    probs.append(clf.predict_proba(features).flatten()[1])\n",
    "    def print_img():\n",
    "        display(img)\n",
    "        if clf2:\n",
    "            probs.append(clf2.predict_proba(features).flatten()[1])\n",
    "        print('Classification probability:')\n",
    "        print(probs)\n",
    "        print('File:'+fp)\n",
    "    if print_wrong and print_right:\n",
    "        print_img()\n",
    "    elif print_wrong and c!=y_pred:\n",
    "        print_img()\n",
    "    elif print_right and c==y_pred:\n",
    "        print_img()\n",
    "    return clf.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d='cleaned-v1/not-phos/'\n",
    "n = 0\n",
    "for f in os.listdir(d):\n",
    "    n+=1\n",
    "    if not n%50:\n",
    "        print(n)\n",
    "        break\n",
    "    calc_pred(d+f, 0, model, mh, clf2=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d='cleaned-v1/phos/'\n",
    "n=0\n",
    "for f in os.listdir(d):\n",
    "    n+=1\n",
    "    if not n%50:\n",
    "        print(n)\n",
    "        break\n",
    "    calc_pred(d+f, 1, model, mh, clf2=m)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d='../phosifier_test/'\n",
    "for f in os.listdir(d):\n",
    "    calc_pred(d+f, 1, model, m, print_right=True, print_wrong=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d='../phosifier_test/'\n",
    "for f in os.listdir(d):\n",
    "    calc_pred(d+f, 0, model, m, print_right=True, print_wrong=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phos = []\n",
    "not_phos = []\n",
    "d='all/'\n",
    "n=0\n",
    "for f in os.listdir(d):\n",
    "    n+=1\n",
    "    if not n%10:\n",
    "        print(n)\n",
    "    try:\n",
    "        pred = calc_pred(d+f, 1, model, m, print_right=False, print_wrong=False)\n",
    "    except IsADirectoryError:\n",
    "        continue\n",
    "    if not pred:\n",
    "        phos.append(f)\n",
    "    else:\n",
    "        not_phos.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shutil\n",
    "for f in phos:\n",
    "    shutil.move(d+f, 'phos/'+f)\n",
    "    \n",
    "for f in not_phos:\n",
    "    shutil.move(d+f, 'not-phos/'+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shutil\n",
    "for f in phos:\n",
    "    shutil.copy2(d+f, 'phos/'+f)\n",
    "    \n",
    "for f in not_phos:\n",
    "    shutil.copy2(d+f, 'not-phos/'+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(phos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(not_phos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
